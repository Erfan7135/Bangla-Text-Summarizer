{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfGuLpWCQhm6",
        "outputId": "829ad461-c822-474b-f47d-2f2dde01618d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import nltk\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Tokenizer"
      ],
      "metadata": {
        "id": "yPBw6GenRB2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class sentTokenizing:\n",
        "    def sentTokenize(self,gettingText):\n",
        "        dataToReSize=[]\n",
        "        data=[]\n",
        "        cleanText=''\n",
        "        for i in gettingText:\n",
        "            if i=='।' or i=='!' or i=='?':\n",
        "                cleanText+=i\n",
        "                dataToReSize.append(''.join(cleanText))\n",
        "                cleanText=''\n",
        "            else:\n",
        "                if i=='\\n' or i=='\\r' or i=='”' or i=='“' or i=='\"':\n",
        "                    continue\n",
        "                else:\n",
        "                    cleanText+=i\n",
        "        #print (dataToReSize)\n",
        "        for i in dataToReSize:\n",
        "            withoutAheadSpace=''\n",
        "            flag=1\n",
        "            for j in i:\n",
        "                if j==' ' and flag:\n",
        "                    continue\n",
        "                else:\n",
        "                    flag=0\n",
        "                    withoutAheadSpace+=j\n",
        "            data.append(''.join(withoutAheadSpace))\n",
        "        #print(data)\n",
        "\n",
        "        return data"
      ],
      "metadata": {
        "id": "fUZw9V7sQ-Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wordcounter"
      ],
      "metadata": {
        "id": "AO8heG_yepq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class word:\n",
        "    def sentToWord(self,gettingData):\n",
        "        cleanSent=''\n",
        "        for i in gettingData:\n",
        "            for j in i:\n",
        "                if j=='”' or j=='“' or j=='\"' or j==',' or j=='‘' or j=='’':\n",
        "                    cleanSent+=' '\n",
        "                    continue\n",
        "                elif j=='!' or j=='?' or j=='।':\n",
        "                    cleanSent+=' '\n",
        "                    continue\n",
        "                elif j=='(' or j=='{' or j=='}' or j=='[' or j==']':\n",
        "                    cleanSent+=' '\n",
        "                else:\n",
        "                    if j=='-' or j==':' or j==')':\n",
        "                        cleanSent+=' '\n",
        "                    else:\n",
        "                        cleanSent+=j\n",
        "        return nltk.word_tokenize(cleanSent)\n",
        "\n",
        "    def wordCount(self,gettingData):\n",
        "        b = self.sentToWord(gettingData)\n",
        "        return len(b)"
      ],
      "metadata": {
        "id": "2y9iav9tep5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9kYPiVQNe0KJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DL Model"
      ],
      "metadata": {
        "id": "mBcWqdjbROra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceSummarizer:\n",
        "  def __init__(self, threshold=0.7):\n",
        "    self.model = SGDClassifier(loss=\"log_loss\", learning_rate=\"adaptive\", eta0=0.01)\n",
        "\n",
        "  def getweightbywords(self, content_sentences):\n",
        "    weights=[]\n",
        "    wc = 0\n",
        "    for i in content_sentences:\n",
        "      wc=wc + word().wordCount(i)\n",
        "    for i in content_sentences:\n",
        "      wcpl = word().wordCount(i)\n",
        "      weights.append(wcpl/wc)\n",
        "    return weights\n",
        "\n",
        "  def getweightbysimilarity(self, content_sentences):\n",
        "    weights=[]\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    text_vector = vectorizer.fit_transform(content_sentences)\n",
        "\n",
        "    for i in content_sentences:\n",
        "      sentence_vector = vectorizer.transform([i])\n",
        "      weights.append(cosine_similarity(sentence_vector, text_vector)[0][0])\n",
        "    # print(weights)\n",
        "    return weights\n",
        "\n",
        "  def getsummaryvalue(self, content_sentences, summary_sentences):\n",
        "    s = []\n",
        "    for i in content_sentences:\n",
        "        if i in summary_sentences:\n",
        "          s.append(1)\n",
        "        else:\n",
        "          s.append(0)\n",
        "    return s\n",
        "\n",
        "\n",
        "  def fit(self, content_sentences, summary_sentences):\n",
        "    #get weight for every sentences\n",
        "    w_weights = self.getweightbywords(content_sentences)\n",
        "    s_weights = self.getweightbysimilarity(content_sentences)\n",
        "    #get summary_value\n",
        "    s = self.getsummaryvalue(content_sentences, summary_sentences)\n",
        "    # Combine features\n",
        "    X = np.array([[f1, f2] for f1, f2 in zip(w_weights, s_weights)])\n",
        "    # Use partial_fit to update the model incrementally\n",
        "    self.model.partial_fit(X, s, classes=[0,1])\n",
        "\n",
        "\n",
        "  def predict(self, content_sentences):\n",
        "    #get weight for every sentences\n",
        "    w_weights = self.getweightbywords(content_sentences)\n",
        "    s_weights = self.getweightbysimilarity(content_sentences)\n",
        "\n",
        "    # X = np.array([[w_weights, s_weights]])\n",
        "    X = np.array([[f1, f2] for f1, f2 in zip(w_weights, s_weights)])\n",
        "    prediction = self.model.predict(X)\n",
        "    print(\"predictions :\", prediction)\n",
        "\n",
        "    p=0\n",
        "    for i in range(len(prediction)):\n",
        "      if prediction[i]>=0.7:\n",
        "        p=p+1\n",
        "\n",
        "    n=len(content_sentences)\n",
        "\n",
        "    if n > 3 and p > int(n / 3):\n",
        "      # Calculate product for each sentence\n",
        "      raw_predictions = [(1/f1) * f2 for f1, f2 in zip(w_weights, s_weights)]\n",
        "\n",
        "      # Convert raw_predictions to a NumPy array\n",
        "      data = [[x] for x in raw_predictions]\n",
        "\n",
        "      # Scale the predictions using min-max scaling\n",
        "      scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "      scaled_data = scaler.fit_transform(data)\n",
        "      prediction = [x[0] for x in scaled_data]\n",
        "      print(prediction)\n",
        "\n",
        "\n",
        "    summary = \"\"\n",
        "    for i in range(len(prediction)):\n",
        "      # print(content_sentences[i])\n",
        "      if prediction[i]>=0.5:\n",
        "        summary = summary + content_sentences[i]\n",
        "\n",
        "    return summary\n",
        "\n",
        "  def savemodel(self):\n",
        "      \"\"\"Saves the trained model to a file.\"\"\"\n",
        "      with open(\"summary_model.pkl\", \"wb\") as f:\n",
        "          pickle.dump(self, f)\n",
        "\n",
        "  def loadmodel(self):\n",
        "      \"\"\"Loads a pre-trained model from a file.\"\"\"\n",
        "      with open(\"summary_model.pkl\", \"rb\") as f:\n",
        "          loaded_model = pickle.load(f)\n",
        "          self.__dict__ = loaded_model.__dict__  # Update current object with loaded attributes\n",
        "\n"
      ],
      "metadata": {
        "id": "WHZ0AmZERONr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing model with simple data"
      ],
      "metadata": {
        "id": "B90S3AlE6Axk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content_data = [\n",
        "    \"This is the first sentence.\",\n",
        "    \"This is the second sentence.\",\n",
        "    \"This is the third sentence.\",\n",
        "    \"Hello world\"\n",
        "]\n",
        "\n",
        "summary_data = [\n",
        "    \"This is the first sentence.\",\n",
        "    \"This is the third sentence.\"\n",
        "]\n",
        "\n",
        "test_data = [\n",
        "    \"This is the first sentence.\",\n",
        "    \"This is the second sentence.\",\n",
        "    \"This is the third sentence\",\n",
        "    \"This is the fourth sentence\",\n",
        "    \"This is the fifth sentence.\",\n",
        "    \"Hello world\",\n",
        "    \"Heloo Bnagladesh\"\n",
        "]\n",
        "\n",
        "model = SentenceSummarizer()\n",
        "model.fit(content_data, summary_data)\n",
        "generated_summary = model.predict(test_data)\n",
        "print(\"Generated Summary:\")\n",
        "# for sentence in generated_summary:\n",
        "#     print(sentence)\n",
        "print(generated_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgkOECI0SQx3",
        "outputId": "b1423268-d46b-491b-c431-f04d8b1f6cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions : [1 1 1 1 1 1 1]\n",
            "[1.0, 0.5380509132588067, 0.6456610959105681, 0.6456610959105681, 0.5380509132588067, 0.0, 0.0]\n",
            "Generated Summary:\n",
            "This is the first sentence.This is the second sentence.This is the third sentenceThis is the fourth sentenceThis is the fifth sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model with dataset and saving the model values"
      ],
      "metadata": {
        "id": "wyuC3dR16IsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('summary_dataset_1.csv')\n",
        "model = SentenceSummarizer()\n",
        "for _,row in df.iterrows():\n",
        "  try:\n",
        "    c = sentTokenizing().sentTokenize(row['content'])\n",
        "    s = sentTokenizing().sentTokenize(row['summary'])\n",
        "    model.fit(c,s)\n",
        "  except:\n",
        "    a = None\n",
        "\n",
        "test = \"মামলা, আদালতে ছোটাছুটির মধ্যেও যুক্তরাষ্ট্রের পেসিডেন্ট পদে রিপাবলিকান পার্টির মনোনয়ন দৌঁড়ে অনেকটাই এগিয়ে ডোনাল্ড ট্রাম্প। সর্বশেষ সাউথ ক্যারোলাইনায় দলের প্রাইমারিতে বড় ব্যবধানে হারিয়েছেন জাতিসংঘে যুক্তরাষ্ট্রের সাবেক রাষ্ট্রদূত নিকি হেইলিকে। নানা অনিশ্চয়তা কাটিয়ে দলীয় মনোনয়নের দৌড়ে ডোনাল্ড ট্রাম্পের বেশ সম্ভাবনা দেখা যাচ্ছে। এর মধ্যেই তিনি নিজের জয়ের ব্যাপারে আত্মবিশ্বাসী হয়ে হুঁশিয়ারি দিয়েছেন প্রেসিডেন্ট জো বাইডেনকে। বাইডেন, ইউ আর ফায়ারড্! গেট আউট, গেট আউট! আসছে নভেম্বরে জো বাইডেনের চোখে চোখ রেখে এই কথাটা বলবেন, ফেব্রুয়ারিতেই সেই ঘোষণা দিয়ে রাখছেন ডোনাল্ড ট্রাম্প। সাউথ ক্যারোলাইনায় দলের প্রাইমারিতে নিকি হেইলির বিরুদ্ধে বড় জয়ের পর রিপাবলিকানদের প্রেসিডেন্ট প্রার্থী হতে এক ধাপ এগিয়ে গেলেন তিনি। দ্বিতীয়বার তার প্রেসিডেন্ট পদে মনোনয়ন পাওয়া নিয়ে ব্যাপক সন্দেহ ছিল খোদ রিপাবলিকান দলের মধ্যেই। কিন্তু এখন মনোনয়নের দৌড়ে তার সাথে রয়েছেন মাত্র একজন প্রার্থী, তাও ট্রাম্প থেকে বেশ খানিকটা পিছিয়ে। সাউথ ক্যারোলাইনা হেইলির নিজের রাজ্য হওয়ায় সাবেক রাষ্ট্রপতির জয়টা বেশি গুরুত্বপূর্ণ। যদিও নিকি হেইলি এখনই লড়াই ছাড়ছেন না। তিনি অন্ততঃ ‘সুপার টুইসডে’ পর্যন্ত প্রতিযোগিতায় থাকার অঙ্গীকার পুনর্ব্যক্ত করেছেন। মার্চের পাঁচ তারিখ সেই মঙ্গলবার। সেদিন ১৬ টি রাজ্যের রিপাবলিকানরা তাদের রায় জানাবেন। সাউথ ক্যারোলাইনার জয় উদযাপন করার সময় মি. ট্রাম্প মিজ হেইলির কথা একবারও উল্লেখ করেননি। তার নজর নভেম্বরের সাধারণ নির্বাচনের দিকে। হোয়াইট হাউসে তারই উত্তরসূরি বাইডেনের সাথে একটি ‘রি-ম্যাচ’ বা পুনঃ লড়াইয়ের সম্ভাবনা এখন প্রবল। শনিবারের ফলাফলের পরে দলের ঐক্যের প্রশংসা করেছেন ট্রাম্প। বলেছেন, এমন মনোভাব আগে কখনও ছিল না। আমি রিপাবলিকান পার্টিকে এতটা ঐক্যবদ্ধ কখনও দেখিনি।\"\n",
        "t = sentTokenizing().sentTokenize(test)\n",
        "print(t)\n",
        "generated_summary = model.predict(t)\n",
        "print(\"Generated Summary:\")\n",
        "# for sentence in generated_summary:\n",
        "#     print(sentence)\n",
        "print(generated_summary)\n",
        "# model.savemodel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihKeKIu_QrsE",
        "outputId": "6160d131-ffc0-4e61-9feb-db6e477b150c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['মামলা, আদালতে ছোটাছুটির মধ্যেও যুক্তরাষ্ট্রের পেসিডেন্ট পদে রিপাবলিকান পার্টির মনোনয়ন দৌঁড়ে অনেকটাই এগিয়ে ডোনাল্ড ট্রাম্প।', 'সর্বশেষ সাউথ ক্যারোলাইনায় দলের প্রাইমারিতে বড় ব্যবধানে হারিয়েছেন জাতিসংঘে যুক্তরাষ্ট্রের সাবেক রাষ্ট্রদূত নিকি হেইলিকে।', 'নানা অনিশ্চয়তা কাটিয়ে দলীয় মনোনয়নের দৌড়ে ডোনাল্ড ট্রাম্পের বেশ সম্ভাবনা দেখা যাচ্ছে।', 'এর মধ্যেই তিনি নিজের জয়ের ব্যাপারে আত্মবিশ্বাসী হয়ে হুঁশিয়ারি দিয়েছেন প্রেসিডেন্ট জো বাইডেনকে।', 'বাইডেন, ইউ আর ফায়ারড্!', 'গেট আউট, গেট আউট!', 'আসছে নভেম্বরে জো বাইডেনের চোখে চোখ রেখে এই কথাটা বলবেন, ফেব্রুয়ারিতেই সেই ঘোষণা দিয়ে রাখছেন ডোনাল্ড ট্রাম্প।', 'সাউথ ক্যারোলাইনায় দলের প্রাইমারিতে নিকি হেইলির বিরুদ্ধে বড় জয়ের পর রিপাবলিকানদের প্রেসিডেন্ট প্রার্থী হতে এক ধাপ এগিয়ে গেলেন তিনি।', 'দ্বিতীয়বার তার প্রেসিডেন্ট পদে মনোনয়ন পাওয়া নিয়ে ব্যাপক সন্দেহ ছিল খোদ রিপাবলিকান দলের মধ্যেই।', 'কিন্তু এখন মনোনয়নের দৌড়ে তার সাথে রয়েছেন মাত্র একজন প্রার্থী, তাও ট্রাম্প থেকে বেশ খানিকটা পিছিয়ে।', 'সাউথ ক্যারোলাইনা হেইলির নিজের রাজ্য হওয়ায় সাবেক রাষ্ট্রপতির জয়টা বেশি গুরুত্বপূর্ণ।', 'যদিও নিকি হেইলি এখনই লড়াই ছাড়ছেন না।', 'তিনি অন্ততঃ ‘সুপার টুইসডে’ পর্যন্ত প্রতিযোগিতায় থাকার অঙ্গীকার পুনর্ব্যক্ত করেছেন।', 'মার্চের পাঁচ তারিখ সেই মঙ্গলবার।', 'সেদিন ১৬ টি রাজ্যের রিপাবলিকানরা তাদের রায় জানাবেন।', 'সাউথ ক্যারোলাইনার জয় উদযাপন করার সময় মি. ট্রাম্প মিজ হেইলির কথা একবারও উল্লেখ করেননি।', 'তার নজর নভেম্বরের সাধারণ নির্বাচনের দিকে।', 'হোয়াইট হাউসে তারই উত্তরসূরি বাইডেনের সাথে একটি ‘রি-ম্যাচ’ বা পুনঃ লড়াইয়ের সম্ভাবনা এখন প্রবল।', 'শনিবারের ফলাফলের পরে দলের ঐক্যের প্রশংসা করেছেন ট্রাম্প।', 'বলেছেন, এমন মনোভাব আগে কখনও ছিল না।', 'আমি রিপাবলিকান পার্টিকে এতটা ঐক্যবদ্ধ কখনও দেখিনি।']\n",
            "predictions : [1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Generated Summary:\n",
            "মামলা, আদালতে ছোটাছুটির মধ্যেও যুক্তরাষ্ট্রের পেসিডেন্ট পদে রিপাবলিকান পার্টির মনোনয়ন দৌঁড়ে অনেকটাই এগিয়ে ডোনাল্ড ট্রাম্প।নানা অনিশ্চয়তা কাটিয়ে দলীয় মনোনয়নের দৌড়ে ডোনাল্ড ট্রাম্পের বেশ সম্ভাবনা দেখা যাচ্ছে।দ্বিতীয়বার তার প্রেসিডেন্ট পদে মনোনয়ন পাওয়া নিয়ে ব্যাপক সন্দেহ ছিল খোদ রিপাবলিকান দলের মধ্যেই।কিন্তু এখন মনোনয়নের দৌড়ে তার সাথে রয়েছেন মাত্র একজন প্রার্থী, তাও ট্রাম্প থেকে বেশ খানিকটা পিছিয়ে।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load saved model and predict summary of new text"
      ],
      "metadata": {
        "id": "2pCLH5gQ6T8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=SentenceSummarizer()\n",
        "model.loadmodel()\n",
        "test = \"বেনাপোলের অবকাঠামোগত উন্নয়নসহ আমদানি-রপ্তানি বাণিজ্যের গতি ফেরাতে বেনাপোল-যশোর মহাসড়ক ৬ লেনে উন্নতকরাসহ বাইপাস সড়কের প্রশস্তকরণ, পণ্য লোড আনলোডের সরঞ্জাম এবং জনবল বৃদ্ধির লক্ষে রবিবার বিকেলে সড়ক ও জনপথসহ বিশ্ব ব্যাংকের ১৭ সদস্যের একটি প্রতিনিধিদল বেনাপোল বন্দর ও চেকপোস্ট এলাকা পরিদর্শন করেছেন।এর আগে বেনাপোল বন্দর প্যাসেজ্ঞার টার্মিনালের কনফারেন্স রুমে বন্দর, কাস্টম ও সিএন্ডএফ এজেন্ট ও বন্দর ব্যবহারকারী বিভিন্ন সংগঠনের নেতা ও প্রশাসনের কর্মকর্তাদের সাথে মত বিনিময় করেন প্রতিনিধিদলটি। উন্নয়ন কর্মকাণ্ডের পূর্ব প্রস্ততি হিসেবে প্রতিনিধি দলের বেনাপোল পরিদর্শন বলে জানান বন্দর সংশ্লিষ্টরা।বাংলাদেশ সড়ক ও জনপথের অতিরিক্ত প্রধান প্রকৌশলী রেজা আহম্মেদ জাবের প্রতিনিধিদলের নেতৃত্ব দেন। এ সময় উপস্থিত ছিলেন, বিশ্ব ব্যাংকের প্রতিনিধি মুন্নি জাহান, বাংলাদেশ স্থলবন্দর কর্তৃপক্ষের তত্বাবধায়ক প্রকৌশলী মোহাম্মদ হাসান আলী, স্থলবন্দর বেনাপোল উপপরিচালক মামুন কবির তরফদার, বেনাপোল কাস্টমের সহকারী কমিশনার উত্তম কুমার চাকমা, বন্দরের সহকারী পরিচালক মেহেদী হাসান, বেনাপোল সিএন্ডএফ এজেন্ট এসোসিয়েশন সভাপতি মফিজুর রহমান সজনসহ ভারত, নেপাল, নাইজেরিয়াসহ বিভিন্ন দেশের প্রতিনিধিরা।\"\n",
        "t = sentTokenizing().sentTokenize(test)\n",
        "print(t)\n",
        "generated_summary = model.predict(t)\n",
        "print(generated_summary)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzfF_lLqUoKJ",
        "outputId": "fe15c534-8ff0-4d42-9ce5-89b77d3695fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['বেনাপোলের অবকাঠামোগত উন্নয়নসহ আমদানি-রপ্তানি বাণিজ্যের গতি ফেরাতে বেনাপোল-যশোর মহাসড়ক ৬ লেনে উন্নতকরাসহ বাইপাস সড়কের প্রশস্তকরণ, পণ্য লোড আনলোডের সরঞ্জাম এবং জনবল বৃদ্ধির লক্ষে রবিবার বিকেলে সড়ক ও জনপথসহ বিশ্ব ব্যাংকের ১৭ সদস্যের একটি প্রতিনিধিদল বেনাপোল বন্দর ও চেকপোস্ট এলাকা পরিদর্শন করেছেন।', 'এর আগে বেনাপোল বন্দর প্যাসেজ্ঞার টার্মিনালের কনফারেন্স রুমে বন্দর, কাস্টম ও সিএন্ডএফ এজেন্ট ও বন্দর ব্যবহারকারী বিভিন্ন সংগঠনের নেতা ও প্রশাসনের কর্মকর্তাদের সাথে মত বিনিময় করেন প্রতিনিধিদলটি।', 'উন্নয়ন কর্মকাণ্ডের পূর্ব প্রস্ততি হিসেবে প্রতিনিধি দলের বেনাপোল পরিদর্শন বলে জানান বন্দর সংশ্লিষ্টরা।', 'বাংলাদেশ সড়ক ও জনপথের অতিরিক্ত প্রধান প্রকৌশলী রেজা আহম্মেদ জাবের প্রতিনিধিদলের নেতৃত্ব দেন।', 'এ সময় উপস্থিত ছিলেন, বিশ্ব ব্যাংকের প্রতিনিধি মুন্নি জাহান, বাংলাদেশ স্থলবন্দর কর্তৃপক্ষের তত্বাবধায়ক প্রকৌশলী মোহাম্মদ হাসান আলী, স্থলবন্দর বেনাপোল উপপরিচালক মামুন কবির তরফদার, বেনাপোল কাস্টমের সহকারী কমিশনার উত্তম কুমার চাকমা, বন্দরের সহকারী পরিচালক মেহেদী হাসান, বেনাপোল সিএন্ডএফ এজেন্ট এসোসিয়েশন সভাপতি মফিজুর রহমান সজনসহ ভারত, নেপাল, নাইজেরিয়াসহ বিভিন্ন দেশের প্রতিনিধিরা।']\n",
            "predictions : [1 0 1 0 0]\n",
            "[0.9999999999999999, 0.0819230907555894, 0.7770318850715086, 0.47740878866501835, 0.0]\n",
            "বেনাপোলের অবকাঠামোগত উন্নয়নসহ আমদানি-রপ্তানি বাণিজ্যের গতি ফেরাতে বেনাপোল-যশোর মহাসড়ক ৬ লেনে উন্নতকরাসহ বাইপাস সড়কের প্রশস্তকরণ, পণ্য লোড আনলোডের সরঞ্জাম এবং জনবল বৃদ্ধির লক্ষে রবিবার বিকেলে সড়ক ও জনপথসহ বিশ্ব ব্যাংকের ১৭ সদস্যের একটি প্রতিনিধিদল বেনাপোল বন্দর ও চেকপোস্ট এলাকা পরিদর্শন করেছেন।উন্নয়ন কর্মকাণ্ডের পূর্ব প্রস্ততি হিসেবে প্রতিনিধি দলের বেনাপোল পরিদর্শন বলে জানান বন্দর সংশ্লিষ্টরা।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading saved model, predict data from csv file & saving the content summary pair"
      ],
      "metadata": {
        "id": "-K-ZgiGiKDNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=SentenceSummarizer()\n",
        "model.loadmodel()\n",
        "df = pd.read_csv('bensumm_data.csv')\n",
        "new_df = pd.DataFrame(columns=['content', 'summary', 'bensumm', 'dl'])\n",
        "for _,row in df.iterrows():\n",
        "  try:\n",
        "    text = sentTokenizing().sentTokenize(row['content'])\n",
        "    summary = model.predict(text)\n",
        "    new_df = new_df.append({'content': row['content'], 'summary': row['summary'], 'bensumm': row['bensumm'], 'dl': summary}, ignore_index=True)\n",
        "  except:\n",
        "    summary = None\n",
        "\n",
        "new_df.to_csv('final_data.csv')"
      ],
      "metadata": {
        "id": "SqVyOt4kJzMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('final_data.csv')\n",
        "print(df['content'][0])\n",
        "print(df['summary'][0])\n",
        "print(df['bensumm'][0])\n",
        "print(df['dl'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90SNIvrkVhbn",
        "outputId": "9cfcf4b0-71ab-4dcd-ae87-98ca04f06d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ধর্মীয় অনুভূতিতে আঘাতের অভিযোগে করা আরও ১০ মামলায় হাইকোর্ট থেকে জামিন পেয়েছেন সাবেক মন্ত্রী আবদুল লতিফ সিদ্দিকী। বিচারপতি মো. নিজামুল হক ও বিচারপতি মো. ফরিদ আহমদ শিবলীর সমন্বয়ে ঘটিত হাইকোর্ট বেঞ্চ আজ মঙ্গলবার এ আদেশ দেন। আদালতে লতিফ সিদ্দিকীর পক্ষে শুনানি করেন আইনজীবী জ্যোতির্ময় বড়ুয়া। রাষ্ট্রপক্ষে ছিলেন ডেপুটি অ্যাটর্নি জেনারেল শেখ এ কে এম মনিরুজ্জামান। এর আগে গত ২৬ মে ধর্মীয় অনুভূতিতে আঘাতের অভিযোগে করা আরও সাত মামলায় সাবেক এই মন্ত্রীকে ছয় মাসের অন্তর্বর্তী জামিন দিয়েছেন হাইকোর্ট। একই সঙ্গে এসব মামলার কার্যক্রম ছয় মাসের জন্য স্থগিত করেছিলেন আদালত। গত বছর সেপ্টেম্বরে যুক্তরাষ্ট্রের নিউইয়র্কে এক অনুষ্ঠানে হজ ও তাবলিগ জামাত নিয়ে বিরূপ মন্তব্য করে সমালোচনার মুখে পড়েন আবদুল লতিফ সিদ্দিকী। এ ঘটনার পর আওয়ামী লীগের সভাপতিমণ্ডলীর এই সদস্য দল থেকে বহিষ্কৃত হন। একই ঘটনায় ধর্মীয় অনুভূতিতে আঘাত ও কটূক্তির অভিযোগে তাঁর বিরুদ্ধে রাজধানী ঢাকাসহ দেশের বিভিন্ন জেলায় বেশ কয়েকটি মামলা হয়। নির্ধারিত সময়ে আদালতে হাজির না হওয়ায় প্রতিটি মামলায় তাঁর বিরুদ্ধে গ্রেপ্তারি পরোয়ানা জারি করেন আদালত। গত বছরের ২৫ নভেম্বর ধানমন্ডি থানায় আত্মসমর্পণ করার পর আদালত তাঁকে কারাগারে পাঠানোর নির্দেশ দেন। মঙ্গলবার লতিফ সিদ্দিকীর আবেদনের ওপর শুনানি করে বিচারপতি মো. নিজামুল হক ও বিচারপতি মো. ফরিদ আহমদ শিবলীর বেঞ্চ রুলসহ এই আদেশ দেয়। এরমধ্যে চাঁপাইনবাবগঞ্জ, লক্ষ্মীপুর ও ঢাকাল একটি করে এবং চট্টগ্রামের সাতটি মামলা রয়েছে। তবে একই অভিযোগে আরও পাঁচটি মামলা থাকায় আওয়ামী লীগের বহিষ্কৃত নেতা লতিফ এখনই মুক্তি পাচ্ছেন না। আদালতে তার পক্ষে শুনানি করেন ব্যারিস্টার জ্যোতির্ময় বড়ুয়া। রাষ্ট্রপক্ষে ছিলেন ডেপুটি অ্যাটর্নি জেনারেল শেখ এ কে এম মনিরুজ্জামান কবির। এই দশ মামলায় লতিফকে অন্তবর্তীকালীন জামিন দেওয়ার পাশাপাশি মামলাগুলোর কার্যক্রম ছয় মাসের জন্য স্থগিত করেছে আদালত। এসব মামলা কেন বাতিল করা হবে না তা জানতে চেয়ে একটি রুলও জারি করা হয়েছে, মামলার বাদী ও সরকারকে চার সপ্তাহের মধ্যে যার জবাব দিতে হবে। এর আগে ঢাকার হাকিম আদালত ও জজ আদালত এসব মামলায় লতিফের জামিন নাকচ করেছিল। আদেশের পর ডেপুটি অ্যাটর্নি জেনারেল মনিরুজ্জামান কবির বলেন, \\\"এ নিয়ে মোট ১৭টি মামলায় লতিফ সিদ্দিকী জামিন পেলেন। তবে আরও পাঁচটি মামলা থাকায় তিনি আপাতত মুক্তি পাচ্ছেন না।\\\"\n",
            "ধর্মীয় অনুভূতিতে আঘাতের অভিযোগে করা আরও ১০ মামলায় হাইকোর্ট থেকে জামিন পেয়েছেন সাবেক মন্ত্রী আবদুল লতিফ সিদ্দিকী|গত বছর সেপ্টেম্বরে যুক্তরাষ্ট্রের নিউইয়র্কে এক অনুষ্ঠানে হজ ও তাবলিগ জামাত নিয়ে বিরূপ মন্তব্য করে সমালোচনার মুখে পড়েন আবদুল লতিফ সিদ্দিকী| নির্ধারিত সময়ে আদালতে হাজির না হওয়ায় প্রতিটি মামলায় তাঁর বিরুদ্ধে গ্রেপ্তারি পরোয়ানা জারি করেন আদালত|এই দশ মামলায় লতিফকে অন্তবর্তীকালীন জামিন দেওয়ার পাশাপাশি মামলাগুলোর কার্যক্রম ছয় মাসের জন্য স্থগিত করেছে আদালত|এসব মামলা কেন বাতিল করা হবে না তা জানতে চেয়ে একটি রুলও জারি করা হয়েছে, মামলার বাদী ও সরকারকে চার সপ্তাহের মধ্যে যার জবাব দিতে হবে| আদেশের পর ডেপুটি অ্যাটর্নি জেনারেল মনিরুজ্জামান কবির বলেন, \\\"এ নিয়ে মোট ১৭টি মামলায় লতিফ সিদ্দিকী জামিন পেলেন। তবে আরও পাঁচটি মামলা থাকায় তিনি আপাতত মুক্তি পাচ্ছেন না।\\\"\n",
            "\n",
            "ধর্মীয় অনুভূতিতে আঘাতের অভিযোগে করা আরও ১০ মামলায় হাইকোর্ট থেকে জামিন পেয়েছেন সাবেক মন্ত্রী আবদুল লতিফ সিদ্দিকী।\n",
            "বিচারপতি মো. নিজামুল হক ও বিচারপতি মো. ফরিদ আহমদ শিবলীর সমন্বয়ে ঘটিত হাইকোর্ট বেঞ্চ আজ মঙ্গলবার এ আদেশ দেন।\n",
            "আদালতে লতিফ সিদ্দিকীর পক্ষে শুনানি করেন আইনজীবী জ্যোতির্ময় বড়ুয়া।\n",
            "রাষ্ট্রপক্ষে ছিলেন ডেপুটি অ্যাটর্নি জেনারেল শেখ এ কে এম মনিরুজ্জামান।\n",
            "একই সঙ্গে এসব মামলার কার্যক্রম ছয় মাসের জন্য স্থগিত করেছিলেন আদালত।\n",
            "গত বছর সেপ্টেম্বরে যুক্তরাষ্ট্রের নিউইয়র্কে এক অনুষ্ঠানে হজ ও তাবলিগ জামাত নিয়ে বিরূপ মন্তব্য করে সমালোচনার মুখে পড়েন আবদুল লতিফ সিদ্দিকী।\n",
            "এ ঘটনার পর আওয়ামী লীগের সভাপতিমণ্ডলীর এই সদস্য দল থেকে বহিষ্কৃত হন।\n",
            "গত বছরের ২৫ নভেম্বর ধানমন্ডি থানায় আত্মসমর্পণ করার পর আদালত তাঁকে কারাগারে পাঠানোর নির্দেশ দেন।\n",
            "তবে একই অভিযোগে আরও পাঁচটি মামলা থাকায় আওয়ামী লীগের বহিষ্কৃত নেতা লতিফ এখনই মুক্তি পাচ্ছেন না।\n",
            "এসব মামলা কেন বাতিল করা হবে না তা জানতে চেয়ে একটি রুলও জারি করা হয়েছে, মামলার বাদী ও সরকারকে চার সপ্তাহের মধ্যে যার জবাব দিতে হবে।\n",
            "আদেশের পর ডেপুটি অ্যাটর্নি জেনারেল মনিরুজ্জামান কবির বলেন, \\এ নিয়ে মোট ১৭টি মামলায় লতিফ সিদ্দিকী জামিন পেলেন।\n",
            "\n",
            "ধর্মীয় অনুভূতিতে আঘাতের অভিযোগে করা আরও ১০ মামলায় হাইকোর্ট থেকে জামিন পেয়েছেন সাবেক মন্ত্রী আবদুল লতিফ সিদ্দিকী।এর আগে গত ২৬ মে ধর্মীয় অনুভূতিতে আঘাতের অভিযোগে করা আরও সাত মামলায় সাবেক এই মন্ত্রীকে ছয় মাসের অন্তর্বর্তী জামিন দিয়েছেন হাইকোর্ট।গত বছর সেপ্টেম্বরে যুক্তরাষ্ট্রের নিউইয়র্কে এক অনুষ্ঠানে হজ ও তাবলিগ জামাত নিয়ে বিরূপ মন্তব্য করে সমালোচনার মুখে পড়েন আবদুল লতিফ সিদ্দিকী।একই ঘটনায় ধর্মীয় অনুভূতিতে আঘাত ও কটূক্তির অভিযোগে তাঁর বিরুদ্ধে রাজধানী ঢাকাসহ দেশের বিভিন্ন জেলায় বেশ কয়েকটি মামলা হয়।তবে একই অভিযোগে আরও পাঁচটি মামলা থাকায় আওয়ামী লীগের বহিষ্কৃত নেতা লতিফ এখনই মুক্তি পাচ্ছেন না।এই দশ মামলায় লতিফকে অন্তবর্তীকালীন জামিন দেওয়ার পাশাপাশি মামলাগুলোর কার্যক্রম ছয় মাসের জন্য স্থগিত করেছে আদালত।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result of content from original text\n",
        "Input csv contains three cloumn\n",
        "'content', 'summary', 'bensumm'"
      ],
      "metadata": {
        "id": "Ngx2jvND4SXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('final_data.csv')\n",
        "\n",
        "sp=[]\n",
        "bp=[]\n",
        "dp=[]\n",
        "k=0\n",
        "for _,row in df.iterrows():\n",
        "  s=0\n",
        "  b=0\n",
        "  d=0\n",
        "  try:\n",
        "    content = sentTokenizing().sentTokenize(row['content'])\n",
        "    summary = sentTokenizing().sentTokenize(row['summary'])\n",
        "    bensumm = sentTokenizing().sentTokenize(row['bensumm'])\n",
        "    dl = sentTokenizing().sentTokenize(row['dl'])\n",
        "    for i in content:\n",
        "      if i in summary:\n",
        "        s=s+1\n",
        "      if i in bensumm:\n",
        "        b=b+1\n",
        "      if i in dl:\n",
        "        d=d+1\n",
        "    sp.append(s/len(content))\n",
        "    bp.append(b/len(content))\n",
        "    dp.append(d/len(content))\n",
        "    k=k+1\n",
        "  except:\n",
        "    a = None\n",
        "\n",
        "print(\"Content from original text :\")\n",
        "print(\"Human Summary :\",sum(sp)*100/k)\n",
        "print(\"BENSUMM Summary :\",sum(bp)*100/k)\n",
        "print(\"DL Summary :\",sum(dp)*100/k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82qDa15fQA7Z",
        "outputId": "83947b8f-7188-4773-c436-72707de24755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content from original text :\n",
            "Human Summary : 3.3256995590469645\n",
            "BENSUMM Summary : 38.552604399072166\n",
            "DL Summary : 18.688705163867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('final_data.csv')\n",
        "\n",
        "hdl=[]\n",
        "dhl=[]\n",
        "k=0\n",
        "for _,row in df.iterrows():\n",
        "  hd=0\n",
        "  dh=0\n",
        "  try:\n",
        "    summary = sentTokenizing().sentTokenize(row['summary'])\n",
        "    dl = sentTokenizing().sentTokenize(row['dl'])\n",
        "    for i in summary:\n",
        "      if i in dl:\n",
        "        hd=hd+1\n",
        "    for i in dl:\n",
        "      if i in summary:\n",
        "        dh=dh+1\n",
        "    hdl.append(hd/len(content))\n",
        "    dhl.append(dh/len(content))\n",
        "    k=k+1\n",
        "  except:\n",
        "    a = None\n",
        "\n",
        "print(\"Compare with Human Summary:\")\n",
        "print(\"DL summary similarity with human:\",sum(hdl)*100/k)\n",
        "print(\"Human summary similarity with DL:\",sum(dhl)*100/k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcabpsCdR7m4",
        "outputId": "2b691800-7ae2-49f7-ad2a-6694ff7b3f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compare with Human Summary:\n",
            "DL summary similarity with human: 0.33670033670033667\n",
            "Human summary similarity with DL: 0.33670033670033667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2b-MWVTN-ycn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('final_data.csv')\n",
        "\n",
        "hdl=[]\n",
        "dhl=[]\n",
        "k=0\n",
        "for _,row in df.iterrows():\n",
        "  hd=0\n",
        "  dh=0\n",
        "  try:\n",
        "    summary = sentTokenizing().sentTokenize(row['bensumm'])\n",
        "    dl = sentTokenizing().sentTokenize(row['dl'])\n",
        "    for i in summary:\n",
        "      if i in dl:\n",
        "        hd=hd+1\n",
        "    for i in dl:\n",
        "      if i in summary:\n",
        "        dh=dh+1\n",
        "    hdl.append(hd/len(content))\n",
        "    dhl.append(dh/len(content))\n",
        "    k=k+1\n",
        "  except:\n",
        "    a = None\n",
        "\n",
        "print(\"Compare with BENSUMM Summary:\")\n",
        "print(\"DL summary similarity with BENSUMM:\",sum(hdl)*100/k)\n",
        "print(\"BENSUMM summary similarity with DL:\",sum(dhl)*100/k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5krSa8E1UPNc",
        "outputId": "92d8f254-ef69-4cbe-eccb-14a2d1546c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compare with BENSUMM Summary:\n",
            "DL summary similarity with BENSUMM: 8.080808080808078\n",
            "BENSUMM summary similarity with DL: 8.249158249158247\n"
          ]
        }
      ]
    }
  ]
}